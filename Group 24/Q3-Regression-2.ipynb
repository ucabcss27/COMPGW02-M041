{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 18:10:19) \n",
      "[GCC 7.2.0]\n",
      "scipy: 1.0.1\n",
      "numpy: 1.14.2\n",
      "matplotlib: 2.1.2\n",
      "pandas: 0.22.0\n",
      "sklearn: 0.19.1\n"
     ]
    }
   ],
   "source": [
    "# Python version\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "# numpy\n",
    "import numpy as np\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: {}'.format(pandas.__version__))\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "import pickle as pickle\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection,linear_model,metrics\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_data(filename, data):\n",
    "\n",
    "    fileObject = open('PickleData/'+filename,'wb') \n",
    "    # this writes the object a to the\n",
    "    # file named 'testfile'\n",
    "    pickle.dump(data,fileObject) \n",
    "\n",
    "    # here we close the fileObject\n",
    "    fileObject.close()\n",
    "    \n",
    "def load_pickle_data(filename):\n",
    "    # we open the file for reading\n",
    "    fileObject = open('PickleData/'+filename,'rb')  \n",
    "    # load the object from the file into var b\n",
    "    return pickle.load(fileObject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pickle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_pickle_data('binary_x_train')\n",
    "y = load_pickle_data('binary_y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = load_pickle_data('binary_x_val')\n",
    "y_val = load_pickle_data('binary_y_val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Binary DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_pickle_data('normal_clean')\n",
    "X = df.drop(['click'],axis=1)\n",
    "y = df['click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_pickle_data('val_normal_clean')\n",
    "X_val = df.drop(['click'],axis=1)\n",
    "y_val = df['click']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle binary dataframe\n",
    "X_undersampled = load_pickle_data('binary_x_train_undersampled')\n",
    "y_undersampled = load_pickle_data('binary_y_train_undersampled')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Logistic regression with parameters set\n",
    "logisticRegr = LogisticRegression(multi_class='multinomial',solver ='newton-cg',max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=500, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(X_undersampled, y_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = logisticRegr.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle data to use for bid estimation\n",
    "pickle_data('Pred_y_logistic_binary', pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_threshold = 0.5\n",
    "bin_pred_y = (pred_y>classification_threshold)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted False</th>\n",
       "      <th>Predicted True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual False</th>\n",
       "      <td>236568</td>\n",
       "      <td>67155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual True</th>\n",
       "      <td>58</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted False  Predicted True\n",
       "Actual False           236568           67155\n",
       "Actual True                58             144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = pd.DataFrame(\n",
    "    confusion_matrix(y_val,bin_pred_y), \n",
    "    columns=[\"Predicted False\", \"Predicted True\"], \n",
    "    index=[\"Actual False\", \"Actual True\"]\n",
    ")\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifical Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88    303723\n",
      "          1       0.00      0.71      0.00       202\n",
      "\n",
      "avg / total       1.00      0.78      0.88    303925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (metrics.classification_report(y_val, bin_pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.74588\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_val.values, bin_pred_y, pos_label=1)\n",
    "print('AUC:',round(metrics.auc(fpr, tpr),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4702658341391338\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_val, bin_pred_y))\n",
    "print('RMSE:',rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 7.63842551549414\n"
     ]
    }
   ],
   "source": [
    "print('Log Loss:',log_loss(y_val, bin_pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegr = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegr.fit(X_undersampled, y_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = LinearRegr.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply logistic signmoid and threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run output through logistic sigmoid function to get values between 0-1\n",
    "#to create a mapping between a scale with range [0,1] and range [−∞,+∞]\n",
    "log_pred_y = logistic.cdf(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set threshold of classification, 0 or 1\n",
    "classification_threshold = 0.5\n",
    "bin_pred_y = (pred_y>classification_threshold)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted False</th>\n",
       "      <th>Predicted True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual False</th>\n",
       "      <td>233578</td>\n",
       "      <td>70145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual True</th>\n",
       "      <td>61</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted False  Predicted True\n",
       "Actual False           233578           70145\n",
       "Actual True                61             141"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = pd.DataFrame(\n",
    "    confusion_matrix(y_val,bin_pred_y), \n",
    "    columns=[\"Predicted False\", \"Predicted True\"], \n",
    "    index=[\"Actual False\", \"Actual True\"]\n",
    ")\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87    303723\n",
      "          1       0.00      0.70      0.00       202\n",
      "\n",
      "avg / total       1.00      0.77      0.87    303925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (metrics.classification_report(y_val, bin_pred_y))\n",
    "# print (metrics.accuracy_score(y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.73353\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_val, bin_pred_y, pos_label=1)\n",
    "print('AUC:',round(metrics.auc(fpr, tpr),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4806222831468941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_val, bin_pred_y))\n",
    "print('RMSE:',rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Log Loss:',log_loss(y_val, bin_pred_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
