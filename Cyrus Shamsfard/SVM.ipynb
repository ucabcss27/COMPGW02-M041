{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from random import randint\n",
    "from sklearn import svm\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score,log_loss,auc\n",
    "from sklearn import model_selection,linear_model,metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_data(filename, data):\n",
    "\n",
    "    fileObject = open('PickleData/'+filename,'wb') \n",
    "    # this writes the object a to the\n",
    "    # file named 'testfile'\n",
    "    pickle.dump(data,fileObject) \n",
    "\n",
    "    # here we close the fileObject\n",
    "    fileObject.close()\n",
    "    \n",
    "def load_pickle_data(filename):\n",
    "    # we open the file for reading\n",
    "    fileObject = open('PickleData/'+filename,'rb')  \n",
    "    # load the object from the file into var b\n",
    "    return pickle.load(fileObject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_pickle_data('normal_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = load_pickle_data('val_normal_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('click',axis=1)\n",
    "y = df['click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_val.drop('click',axis=1)\n",
    "y_val = df_val['click']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersample Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the random under-sampling\n",
    "rus = RandomUnderSampler(return_indices=True)\n",
    "X_resampled, y_resampled, idx_resampled = rus.fit_sample(X, y)\n",
    "# X_res_vis = pca.transform(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 11.908070433324431\n"
     ]
    }
   ],
   "source": [
    "print('Log Loss:',log_loss(y_val, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5871677600555317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_val, pred_y))\n",
    "print('RMSE:',rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5653\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_val, pred_y, pos_label=1)\n",
    "print('AUC:',round(metrics.auc(fpr, tpr),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.66      0.79    303723\n",
      "          1       0.00      0.48      0.00       202\n",
      "\n",
      "avg / total       1.00      0.66      0.79    303925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (metrics.classification_report(y_val, pred_y))\n",
    "# print (metrics.accuracy_score(y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted False</th>\n",
       "      <th>Predicted True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual False</th>\n",
       "      <td>199046</td>\n",
       "      <td>104677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual True</th>\n",
       "      <td>106</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted False  Predicted True\n",
       "Actual False           199046          104677\n",
       "Actual True               106              96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "confusion_matrix = pd.DataFrame(\n",
    "    confusion_matrix(y_val,pred_y), \n",
    "    columns=[\"Predicted False\", \"Predicted True\"], \n",
    "    index=[\"Actual False\", \"Actual True\"]\n",
    ")\n",
    "display(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
